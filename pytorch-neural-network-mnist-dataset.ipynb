{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Guide: https://www.youtube.com/watch?v=Jy4wM2X21u0&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=3","metadata":{}},{"cell_type":"code","source":"# importing necessary packages \n\nimport torch # the library\nimport torch.nn as nn # neural network modules - CNNs, RNNs, Linear\nimport torch.optim as optim # optimizers like SGD, Adam etc\nimport torch.nn.functional as F # Activation Functions\nfrom torch.utils.data import DataLoader, TensorDataset # helps load data, make batches\nimport torchvision.datasets as datasets #datasets on pytorch\nfrom torchvision.datasets import MNIST\nimport torchvision.transforms as transforms # helps transfrom datasets\nimport os\nimport struct\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:24.217783Z","iopub.execute_input":"2025-07-23T01:55:24.218367Z","iopub.status.idle":"2025-07-23T01:55:28.769612Z","shell.execute_reply.started":"2025-07-23T01:55:24.218336Z","shell.execute_reply":"2025-07-23T01:55:28.768462Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Basically nn.Module is the parent class that contains all the neural network functions which we need. \nTo build a neural network we make a child class \"NN\" which inherits from the parent class. \nTo use the functions defined in the parent class, we use super, and then we initialize our neural network using\nsuper(NN, self).__init__() \nwhere NN is the child class and super allows it to inherit functions from the nn.Module parent.","metadata":{}},{"cell_type":"code","source":"def load_images(file_path):\n    with open(file_path, 'rb') as f:\n        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n    return images\n\ndef load_labels(file_path):\n    with open(file_path, 'rb') as f:\n        magic, num = struct.unpack(\">II\", f.read(8))\n        labels = np.frombuffer(f.read(), dtype=np.uint8)\n    return labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:28.770635Z","iopub.execute_input":"2025-07-23T01:55:28.771485Z","iopub.status.idle":"2025-07-23T01:55:28.778437Z","shell.execute_reply.started":"2025-07-23T01:55:28.771444Z","shell.execute_reply":"2025-07-23T01:55:28.777386Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define file paths\nbase_path = \"/kaggle/input/mnist-dataset/\"  # Adjust this path to your actual dataset\nprint(os.listdir(base_path))\n\ntrain_images = load_images(os.path.join(base_path, \"train-images.idx3-ubyte\"))\ntrain_labels = load_labels(os.path.join(base_path, \"train-labels.idx1-ubyte\"))\n\ntest_images = load_images(os.path.join(base_path, \"t10k-images.idx3-ubyte\"))\ntest_labels = load_labels(os.path.join(base_path, \"t10k-labels.idx1-ubyte\"))\n\n# Confirm shapes\nprint(f\"Train images shape: {train_images.shape}\")\nprint(f\"Train labels shape: {train_labels.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:28.780795Z","iopub.execute_input":"2025-07-23T01:55:28.781125Z","iopub.status.idle":"2025-07-23T01:55:28.907393Z","shell.execute_reply.started":"2025-07-23T01:55:28.781094Z","shell.execute_reply":"2025-07-23T01:55:28.906542Z"}},"outputs":[{"name":"stdout","text":"['t10k-labels-idx1-ubyte', 'train-images.idx3-ubyte', 't10k-images-idx3-ubyte', 't10k-labels.idx1-ubyte', 't10k-images.idx3-ubyte', 'train-labels.idx1-ubyte', 'train-labels-idx1-ubyte', 'train-images-idx3-ubyte']\nTrain images shape: (60000, 28, 28)\nTrain labels shape: (60000,)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"plt.imshow(train_images[0], cmap='gray')\nplt.title(f\"Label: {train_labels[0]}\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:28.908389Z","iopub.execute_input":"2025-07-23T01:55:28.908650Z","iopub.status.idle":"2025-07-23T01:55:29.016197Z","shell.execute_reply.started":"2025-07-23T01:55:28.908629Z","shell.execute_reply":"2025-07-23T01:55:29.015108Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"**CONVERSION FROM NUMPY TO TENSOR**","metadata":{}},{"cell_type":"markdown","source":"When you convert NumPy arrays (like raw pixel values from MNIST) to PyTorch tensors, normalization is critical for effective and stable training of your neural network.\nThe raw images you load from .idx files or images usually have values in the range: 0-255\nBut PyTorch models — especially neural networks — expect inputs in a much smaller range\ndtype: float32\nrange: [0.0, 1.0] or [-1.0, 1.0]\ntensor = torch.from_numpy(array).float() / 255.0\nYou:\n\nConvert to float: neural networks work best with float32\n\nScale to [0, 1]: consistent input scale helps training","metadata":{}},{"cell_type":"code","source":"# https://docs.pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy\ntrain_images_tensor = torch.from_numpy(train_images).float() / 255.0\ntrain_images_tensor = train_images_tensor.unsqueeze(1) # unsqueezes the channel which is required by CNNS\ntrain_labels_tensor = torch.from_numpy(train_labels).long()\ntest_images_tensor = torch.from_numpy(test_images).float() / 255.0\ntest_images_tensor = test_images_tensor.unsqueeze(1)\ntest_labels_tensor = torch.from_numpy(test_labels).long()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.017085Z","iopub.execute_input":"2025-07-23T01:55:29.017444Z","iopub.status.idle":"2025-07-23T01:55:29.254051Z","shell.execute_reply.started":"2025-07-23T01:55:29.017413Z","shell.execute_reply":"2025-07-23T01:55:29.253287Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_227/2008822088.py:2: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n  train_images_tensor = torch.from_numpy(train_images).float() / 255.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\ntest_dataset = TensorDataset(test_images_tensor, test_labels_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.255062Z","iopub.execute_input":"2025-07-23T01:55:29.255362Z","iopub.status.idle":"2025-07-23T01:55:29.260037Z","shell.execute_reply.started":"2025-07-23T01:55:29.255339Z","shell.execute_reply":"2025-07-23T01:55:29.259214Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"'''\nclass Car:\n    def __init__(self):\n        print(\"Car engine started.\")\n\nclass Tesla(Car):\n    def __init__(self):\n        super(Tesla, self).__init__()  # Call the Car class's constructor\n        print(\"Tesla features initialized.\")\n\nmy_car = Tesla()\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.261159Z","iopub.execute_input":"2025-07-23T01:55:29.261448Z","iopub.status.idle":"2025-07-23T01:55:29.283055Z","shell.execute_reply.started":"2025-07-23T01:55:29.261427Z","shell.execute_reply":"2025-07-23T01:55:29.282153Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'\\nclass Car:\\n    def __init__(self):\\n        print(\"Car engine started.\")\\n\\nclass Tesla(Car):\\n    def __init__(self):\\n        super(Tesla, self).__init__()  # Call the Car class\\'s constructor\\n        print(\"Tesla features initialized.\")\\n\\nmy_car = Tesla()\\n'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Create a fully connected neural network\n# https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n\nclass NN(nn.Module): # a new class NN that inherits from nn.Module (which is PyTorch’s base class for all neural networks)\n    def __init__(self, input_size, num_classes): # \n        super(NN, self).__init__() # initialization, super() gives you access to methods in a parent class \n        self.fc1 = nn.Linear(input_size, 50) # Layer 1 input-> 50 nodes\n        self.fc2 = nn.Linear(50, num_classes) # Layer 2 50-> num of classes\n\n    def forward(self, x):\n        #would run on input x\n        x = self.fc1(x) # apply 1st linear tranformation\n        x = F.relu(x) # apply activation\n        x = self.fc2(x) # apply 2nd tranformation\n        return x\n\nmodel = NN(28*28, 10) #image pixel, 10 number of digits\nx = torch.randn(64, 28*28)\nprint(model(x).shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.284062Z","iopub.execute_input":"2025-07-23T01:55:29.284384Z","iopub.status.idle":"2025-07-23T01:55:29.307163Z","shell.execute_reply.started":"2025-07-23T01:55:29.284354Z","shell.execute_reply":"2025-07-23T01:55:29.306228Z"}},"outputs":[{"name":"stdout","text":"torch.Size([64, 10])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.309629Z","iopub.execute_input":"2025-07-23T01:55:29.309886Z","iopub.status.idle":"2025-07-23T01:55:29.329406Z","shell.execute_reply.started":"2025-07-23T01:55:29.309867Z","shell.execute_reply":"2025-07-23T01:55:29.328551Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Hyperparameters\ninput_size = 784 # 28*28\nnum_classes = 10\nbatch_size = 64\nlearning_rate = 0.001\nnum_epochs = 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.330344Z","iopub.execute_input":"2025-07-23T01:55:29.330672Z","iopub.status.idle":"2025-07-23T01:55:29.352910Z","shell.execute_reply.started":"2025-07-23T01:55:29.330642Z","shell.execute_reply":"2025-07-23T01:55:29.351903Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Create data loaders.\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nfor X, y in test_loader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break\n\n# N: Number of images\n# C: channels - grayscale = 1 channel\n#if colored  = rgb, channels = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.353755Z","iopub.execute_input":"2025-07-23T01:55:29.354073Z","iopub.status.idle":"2025-07-23T01:55:29.375496Z","shell.execute_reply.started":"2025-07-23T01:55:29.354044Z","shell.execute_reply":"2025-07-23T01:55:29.374364Z"}},"outputs":[{"name":"stdout","text":"Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\nShape of y: torch.Size([64]) torch.int64\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model = NN(input_size = input_size, num_classes = num_classes).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.376903Z","iopub.execute_input":"2025-07-23T01:55:29.377500Z","iopub.status.idle":"2025-07-23T01:55:29.396991Z","shell.execute_reply.started":"2025-07-23T01:55:29.377461Z","shell.execute_reply":"2025-07-23T01:55:29.395919Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr= learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.397931Z","iopub.execute_input":"2025-07-23T01:55:29.398271Z","iopub.status.idle":"2025-07-23T01:55:29.415451Z","shell.execute_reply.started":"2025-07-23T01:55:29.398248Z","shell.execute_reply":"2025-07-23T01:55:29.414495Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# train NW\nfor epoch in range(num_epochs):\n    for batch_id, (data, targets) in enumerate(train_loader):\n        # Get data to CUDA\n        data = data.to(device = device)\n        targets = targets.to(device = device)\n        # print(data.shape)\n        # converting n-d matrix to 1-d vect\n        # print(data.shape[0]) => 64\n\n        # GET TO CORRECT SHAPE\n        data = data.reshape(data.shape[0], -1)\n        # 64 remains, 1-28-28 flattened\n\n        # Forward Pass\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # Backward Pass\n        optimizer.zero_grad() #set all gradients to zero\n        loss.backward()\n\n        #gradient descent\n        optimizer.step() #update the weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:29.416495Z","iopub.execute_input":"2025-07-23T01:55:29.416784Z","iopub.status.idle":"2025-07-23T01:55:38.562595Z","shell.execute_reply.started":"2025-07-23T01:55:29.416763Z","shell.execute_reply":"2025-07-23T01:55:38.561547Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n    with torch.no_grad():\n        # Loop through the data\n        for x, y in loader:\n\n            # Move data to device\n            x = x.to(device=device)\n            y = y.to(device=device)\n\n            # Get to correct shape\n            x = x.reshape(x.shape[0], -1)\n\n            # Forward pass\n            scores = model(x)\n            _, predictions = scores.max(1)\n\n            # Check how many we got correct\n            num_correct += (predictions == y).sum()\n\n            # Keep track of number of samples\n            num_samples += predictions.size(0)\n\n    model.train()\n    return num_correct / num_samples\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:38.563666Z","iopub.execute_input":"2025-07-23T01:55:38.563998Z","iopub.status.idle":"2025-07-23T01:55:38.572137Z","shell.execute_reply.started":"2025-07-23T01:55:38.563969Z","shell.execute_reply":"2025-07-23T01:55:38.569949Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Check accuracy on training & test to see how good our model\nprint(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\nprint(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:38.574027Z","iopub.execute_input":"2025-07-23T01:55:38.574433Z","iopub.status.idle":"2025-07-23T01:55:39.755366Z","shell.execute_reply.started":"2025-07-23T01:55:38.574409Z","shell.execute_reply":"2025-07-23T01:55:39.753385Z"}},"outputs":[{"name":"stdout","text":"Accuracy on training set: 96.70\nAccuracy on test set: 96.10\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# # load_data\n# # train_dataset = MNIST(root = 'dataset/',train = True, transform = transforms.ToTensor(), download = True)\n# train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True,transform = transforms.ToTensor())\n# # train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n# # load_data\n# # test_dataset = MNIST(root = 'dataset/',train = False, transform = transforms.ToTensor(), download = True)\n# test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transforms.ToTensor())\n# # train_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T01:55:39.757017Z","iopub.execute_input":"2025-07-23T01:55:39.757792Z","iopub.status.idle":"2025-07-23T01:55:39.763209Z","shell.execute_reply.started":"2025-07-23T01:55:39.757748Z","shell.execute_reply":"2025-07-23T01:55:39.762057Z"}},"outputs":[],"execution_count":17}]}